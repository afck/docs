<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="rustdoc">
    <meta name="description" content="API documentation for the Rust `fann` crate.">
    <meta name="keywords" content="rust, rustlang, rust-lang, fann">

    <title>fann - Rust</title>

    <link rel="stylesheet" type="text/css" href="../main.css">

    
    
</head>
<body class="rustdoc">
    <!--[if lte IE 8]>
    <div class="warning">
        This old browser is unsupported and will most likely display funky
        things.
    </div>
    <![endif]-->

    

    <section class="sidebar">
        
        <p class='location'></p><script>window.sidebarCurrent = {name: 'fann', ty: 'mod', relpath: '../'};</script>
    </section>

    <nav class="sub">
        <form class="search-form js-only">
            <div class="search-container">
                <input class="search-input" name="search"
                       autocomplete="off"
                       placeholder="Click or press 'S' to search, '?' for more options..."
                       type="search">
            </div>
        </form>
    </nav>

    <section id='main' class="content mod">
<h1 class='fqn'><span class='in-band'>Crate <a class='mod' href=''>fann</a></span><span class='out-of-band'><span id='render-detail'>
            <a id="toggle-all-docs" href="javascript:void(0)" title="collapse all docs">
                [<span class='inner'>&#x2212;</span>]
            </a>
        </span><a id='src-0' class='srclink' href='../src/fann/lib.rs.html#1-941' title='goto source code'>[src]</a></span></h1>
<div class='docblock'><p>A Rust wrapper for the Fast Artificial Neural Network library.</p>

<p>A new neural network with random weights can be created with the <code>Fann::new</code> method, or, for
different network topologies, with its variants <code>Fann::new_sparse</code> and <code>Fann::new_shortcut</code>.
Existing neural networks can be saved to and loaded from files.</p>

<p>Similarly, training data sets can be loaded from and saved to human-readable files, or training
data can be provided directly to the network as slices of floating point numbers.</p>

<p>Example:</p>
<pre class='rust rust-example-rendered'>
<span class='kw'>extern</span> <span class='kw'>crate</span> <span class='ident'>fann</span>;
<span class='kw'>use</span> <span class='ident'>fann</span>::{<span class='ident'>ActivationFunc</span>, <span class='ident'>Fann</span>, <span class='ident'>TrainAlgorithm</span>, <span class='ident'>QuickpropParams</span>};

<span class='kw'>fn</span> <span class='ident'>main</span>() {
   <span class='comment'>// Create a new network with two input neurons, a hidden layer with three neurons, and one</span>
   <span class='comment'>// output neuron.</span>
   <span class='kw'>let</span> <span class='kw-2'>mut</span> <span class='ident'>fann</span> <span class='op'>=</span> <span class='ident'>Fann</span>::<span class='ident'>new</span>(<span class='kw-2'>&amp;</span>[<span class='number'>2</span>, <span class='number'>3</span>, <span class='number'>1</span>]).<span class='ident'>unwrap</span>();
   <span class='comment'>// Configure the activation functions for the hidden and output neurons.</span>
   <span class='ident'>fann</span>.<span class='ident'>set_activation_func_hidden</span>(<span class='ident'>ActivationFunc</span>::<span class='ident'>SigmoidSymmetric</span>);
   <span class='ident'>fann</span>.<span class='ident'>set_activation_func_output</span>(<span class='ident'>ActivationFunc</span>::<span class='ident'>SigmoidSymmetric</span>);
   <span class='comment'>// Use the Quickprop learning algorithm, with default parameters.</span>
   <span class='comment'>// (Otherwise, Rprop would be used.)</span>
   <span class='ident'>fann</span>.<span class='ident'>set_train_algorithm</span>(<span class='ident'>TrainAlgorithm</span>::<span class='ident'>Quickprop</span>(<span class='ident'>Default</span>::<span class='ident'>default</span>()));
   <span class='comment'>// Train for up to 500000 epochs, displaying progress information after intervals of 1000</span>
   <span class='comment'>// epochs. Stop when the network&#39;s error on the training data drops to 0.001.</span>
   <span class='kw'>let</span> <span class='ident'>max_epochs</span> <span class='op'>=</span> <span class='number'>500000</span>;
   <span class='kw'>let</span> <span class='ident'>epochs_between_reports</span> <span class='op'>=</span> <span class='number'>1000</span>;
   <span class='kw'>let</span> <span class='ident'>desired_error</span> <span class='op'>=</span> <span class='number'>0.001</span>;
   <span class='comment'>// Train directly on data loaded from the file &quot;xor.data&quot;.</span>
   <span class='ident'>fann</span>.<span class='ident'>train_on_file</span>(<span class='string'>&quot;test_files/xor.data&quot;</span>,
                      <span class='ident'>max_epochs</span>,
                      <span class='ident'>epochs_between_reports</span>,
                      <span class='ident'>desired_error</span>).<span class='ident'>unwrap</span>();
   <span class='comment'>// The network now approximates the XOR problem:</span>
   <span class='macro'>assert</span><span class='macro'>!</span>(<span class='ident'>fann</span>.<span class='ident'>run</span>(<span class='kw-2'>&amp;</span>[<span class='op'>-</span><span class='number'>1.0</span>,  <span class='number'>1.0</span>]).<span class='ident'>unwrap</span>()[<span class='number'>0</span>] <span class='op'>&gt;</span> <span class='number'>0.9</span>);
   <span class='macro'>assert</span><span class='macro'>!</span>(<span class='ident'>fann</span>.<span class='ident'>run</span>(<span class='kw-2'>&amp;</span>[ <span class='number'>1.0</span>, <span class='op'>-</span><span class='number'>1.0</span>]).<span class='ident'>unwrap</span>()[<span class='number'>0</span>] <span class='op'>&gt;</span> <span class='number'>0.9</span>);
   <span class='macro'>assert</span><span class='macro'>!</span>(<span class='ident'>fann</span>.<span class='ident'>run</span>(<span class='kw-2'>&amp;</span>[ <span class='number'>1.0</span>,  <span class='number'>1.0</span>]).<span class='ident'>unwrap</span>()[<span class='number'>0</span>] <span class='op'>&lt;</span> <span class='number'>0.1</span>);
   <span class='macro'>assert</span><span class='macro'>!</span>(<span class='ident'>fann</span>.<span class='ident'>run</span>(<span class='kw-2'>&amp;</span>[<span class='op'>-</span><span class='number'>1.0</span>, <span class='op'>-</span><span class='number'>1.0</span>]).<span class='ident'>unwrap</span>()[<span class='number'>0</span>] <span class='op'>&lt;</span> <span class='number'>0.1</span>);
}
</pre>

<p>FANN also supports cascade training, where the network&#39;s topology is changed during training by
adding additional neurons:</p>
<pre class='rust rust-example-rendered'>
<span class='kw'>extern</span> <span class='kw'>crate</span> <span class='ident'>fann</span>;
<span class='kw'>use</span> <span class='ident'>fann</span>::{<span class='ident'>ActivationFunc</span>, <span class='ident'>CascadeParams</span>, <span class='ident'>Fann</span>};

<span class='kw'>fn</span> <span class='ident'>main</span>() {
   <span class='comment'>// Create a new network with two input neurons and one output neuron.</span>
   <span class='kw'>let</span> <span class='kw-2'>mut</span> <span class='ident'>fann</span> <span class='op'>=</span> <span class='ident'>Fann</span>::<span class='ident'>new_shortcut</span>(<span class='kw-2'>&amp;</span>[<span class='number'>2</span>, <span class='number'>1</span>]).<span class='ident'>unwrap</span>();
   <span class='comment'>// Use the default cascade training parameters, but a higher weight multiplier:</span>
   <span class='ident'>fann</span>.<span class='ident'>set_cascade_params</span>(<span class='kw-2'>&amp;</span><span class='ident'>CascadeParams</span> {
                                <span class='ident'>weight_multiplier</span>: <span class='number'>0.6</span>,
                                ..<span class='ident'>CascadeParams</span>::<span class='ident'>default</span>()
                            });
   <span class='comment'>// Add up to 50 neurons, displaying progress information after each.</span>
   <span class='comment'>// Stop when the network&#39;s error on the training data drops to 0.001.</span>
   <span class='kw'>let</span> <span class='ident'>max_neurons</span> <span class='op'>=</span> <span class='number'>50</span>;
   <span class='kw'>let</span> <span class='ident'>neurons_between_reports</span> <span class='op'>=</span> <span class='number'>1</span>;
   <span class='kw'>let</span> <span class='ident'>desired_error</span> <span class='op'>=</span> <span class='number'>0.001</span>;
   <span class='comment'>// Train directly on data loaded from the file &quot;xor.data&quot;.</span>
   <span class='ident'>fann</span>.<span class='ident'>cascadetrain_on_file</span>(<span class='string'>&quot;test_files/xor.data&quot;</span>,
                             <span class='ident'>max_neurons</span>,
                             <span class='ident'>neurons_between_reports</span>,
                             <span class='ident'>desired_error</span>).<span class='ident'>unwrap</span>();
   <span class='comment'>// The network now approximates the XOR problem:</span>
   <span class='macro'>assert</span><span class='macro'>!</span>(<span class='ident'>fann</span>.<span class='ident'>run</span>(<span class='kw-2'>&amp;</span>[<span class='op'>-</span><span class='number'>1.0</span>,  <span class='number'>1.0</span>]).<span class='ident'>unwrap</span>()[<span class='number'>0</span>] <span class='op'>&gt;</span> <span class='number'>0.9</span>);
   <span class='macro'>assert</span><span class='macro'>!</span>(<span class='ident'>fann</span>.<span class='ident'>run</span>(<span class='kw-2'>&amp;</span>[ <span class='number'>1.0</span>, <span class='op'>-</span><span class='number'>1.0</span>]).<span class='ident'>unwrap</span>()[<span class='number'>0</span>] <span class='op'>&gt;</span> <span class='number'>0.9</span>);
   <span class='macro'>assert</span><span class='macro'>!</span>(<span class='ident'>fann</span>.<span class='ident'>run</span>(<span class='kw-2'>&amp;</span>[ <span class='number'>1.0</span>,  <span class='number'>1.0</span>]).<span class='ident'>unwrap</span>()[<span class='number'>0</span>] <span class='op'>&lt;</span> <span class='number'>0.1</span>);
   <span class='macro'>assert</span><span class='macro'>!</span>(<span class='ident'>fann</span>.<span class='ident'>run</span>(<span class='kw-2'>&amp;</span>[<span class='op'>-</span><span class='number'>1.0</span>, <span class='op'>-</span><span class='number'>1.0</span>]).<span class='ident'>unwrap</span>()[<span class='number'>0</span>] <span class='op'>&lt;</span> <span class='number'>0.1</span>);
}
</pre>
</div><h2 id='structs' class='section-header'><a href="#structs">Structs</a></h2>
<table>
                    <tr class=' module-item'>
                        <td><a class='struct' href='struct.BatchParams.html'
                               title='fann::BatchParams'>BatchParams</a></td>
                        <td class='docblock short'>
                             
                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='struct' href='struct.CascadeParams.html'
                               title='fann::CascadeParams'>CascadeParams</a></td>
                        <td class='docblock short'>
                             <p>Parameters for cascade training.</p>

                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='struct' href='struct.Fann.html'
                               title='fann::Fann'>Fann</a></td>
                        <td class='docblock short'>
                             
                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='struct' href='struct.FannError.html'
                               title='fann::FannError'>FannError</a></td>
                        <td class='docblock short'>
                             
                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='struct' href='struct.IncrementalParams.html'
                               title='fann::IncrementalParams'>IncrementalParams</a></td>
                        <td class='docblock short'>
                             
                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='struct' href='struct.QuickpropParams.html'
                               title='fann::QuickpropParams'>QuickpropParams</a></td>
                        <td class='docblock short'>
                             
                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='struct' href='struct.RpropParams.html'
                               title='fann::RpropParams'>RpropParams</a></td>
                        <td class='docblock short'>
                             
                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='struct' href='struct.TrainData.html'
                               title='fann::TrainData'>TrainData</a></td>
                        <td class='docblock short'>
                             
                        </td>
                    </tr>
                </table><h2 id='enums' class='section-header'><a href="#enums">Enums</a></h2>
<table>
                    <tr class=' module-item'>
                        <td><a class='enum' href='enum.ActivationFunc.html'
                               title='fann::ActivationFunc'>ActivationFunc</a></td>
                        <td class='docblock short'>
                             <p>The activation functions used for the neurons during training. They can either be set for a
group of neurons using <code>set_activation_func_hidden</code> and <code>set_activation_func_output</code>, or for a
single neuron using <code>set_activation_func</code>.</p>

                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='enum' href='enum.ErrorFunc.html'
                               title='fann::ErrorFunc'>ErrorFunc</a></td>
                        <td class='docblock short'>
                             <p>Error function used during training.</p>

                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='enum' href='enum.FannErrorType.html'
                               title='fann::FannErrorType'>FannErrorType</a></td>
                        <td class='docblock short'>
                             
                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='enum' href='enum.NetType.html'
                               title='fann::NetType'>NetType</a></td>
                        <td class='docblock short'>
                             <p>Network types</p>

                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='enum' href='enum.StopFunc.html'
                               title='fann::StopFunc'>StopFunc</a></td>
                        <td class='docblock short'>
                             <p>Stop critieria for training.</p>

                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='enum' href='enum.TrainAlgorithm.html'
                               title='fann::TrainAlgorithm'>TrainAlgorithm</a></td>
                        <td class='docblock short'>
                             <p>The Training algorithms used when training on <code>fann_train_data</code> with functions like
<code>fann_train_on_data</code> or <code>fann_train_on_file</code>. The incremental training alters the weights
after each time it is presented an input pattern, while batch only alters the weights once after
it has been presented to all the patterns.</p>

                        </td>
                    </tr>
                </table><h2 id='types' class='section-header'><a href="#types">Type Definitions</a></h2>
<table>
                    <tr class=' module-item'>
                        <td><a class='type' href='type.Connection.html'
                               title='fann::Connection'>Connection</a></td>
                        <td class='docblock short'>
                             
                        </td>
                    </tr>
                
                    <tr class=' module-item'>
                        <td><a class='type' href='type.FannResult.html'
                               title='fann::FannResult'>FannResult</a></td>
                        <td class='docblock short'>
                             
                        </td>
                    </tr>
                </table></section>
    <section id='search' class="content hidden"></section>

    <section class="footer"></section>

    <div id="help" class="hidden">
        <div class="shortcuts">
            <h1>Keyboard shortcuts</h1>
            <dl>
                <dt>?</dt>
                <dd>Show this help dialog</dd>
                <dt>S</dt>
                <dd>Focus the search field</dd>
                <dt>&larrb;</dt>
                <dd>Move up in search results</dd>
                <dt>&rarrb;</dt>
                <dd>Move down in search results</dd>
                <dt>&#9166;</dt>
                <dd>Go to active search result</dd>
            </dl>
        </div>
        <div class="infos">
            <h1>Search tricks</h1>
            <p>
                Prefix searches with a type followed by a colon (e.g.
                <code>fn:</code>) to restrict the search to a given type.
            </p>
            <p>
                Accepted types are: <code>fn</code>, <code>mod</code>,
                <code>struct</code>, <code>enum</code>,
                <code>trait</code>, <code>typedef</code> (or
                <code>tdef</code>).
            </p>
            <p>
                Search functions by type signature (e.g.
                <code>vec -> usize</code>)
            </p>
        </div>
    </div>

    

    <script>
        window.rootPath = "../";
        window.currentCrate = "fann";
        window.playgroundUrl = "";
    </script>
    <script src="../jquery.js"></script>
    <script src="../main.js"></script>
    
    <script async src="../search-index.js"></script>
</body>
</html>